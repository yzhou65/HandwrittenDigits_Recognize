{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_digits\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored,cprint\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K Nearest Neighbours Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################  Euclidean Distance   #########################\n",
    "\n",
    "def euclideanDistance(x1, x2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow((x1[x] - x2[x]), 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################  FInd the Neighbors   #########################\n",
    "\n",
    "\n",
    "def Find_Neighbors(trainingSet, testData, k):\n",
    "    distances = []\n",
    "    \n",
    "    length = len(testData)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testData, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################### Predict the data   ########################\n",
    "\n",
    "def Predict(neighbors):\n",
    "    class_votes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in class_votes:\n",
    "            class_votes[response] += 1\n",
    "        else:\n",
    "            class_votes[response] = 1\n",
    "    sorted_votes = sorted(class_votes.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_votes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################  Find Accuracy of My model     ############################\n",
    "\n",
    "\n",
    "def Find_Accuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        \n",
    "        if testSet[x] == predictions[x]:\n",
    "            correct += 1\n",
    "            print colored(\">>Predicted Result {0} and Actual Result {1}\" \\\n",
    "                          .format(predictions[x],testSet[x]),'green')\n",
    "    \n",
    "        else:\n",
    "            #pass\n",
    "            cprint(\">>Predicted Result {0} and Actual Result {1}\" \\\n",
    "                          .format(predictions[x],testSet[x]),None,'on_red')\n",
    "\n",
    "    return ((correct/float(len(testSet))) * 100.0),correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of digits in dataset Counter({1: 7877, 7: 7293, 3: 7141, 2: 6990, 9: 6958, 0: 6903, 6: 6876, 8: 6825, 4: 6824, 5: 6313})\n"
     ]
    }
   ],
   "source": [
    "##############################  MNIST Digit Training Part for HOG Features  #####################################\n",
    "\n",
    "# Hog Fetures are used for Object Detection. So as our project is about Handwritten digit recognition, we have \n",
    "#     used Hog feature.  \n",
    "\n",
    "\n",
    "# digits = load_digits()\n",
    "# np.unique(digits.target)\n",
    "\n",
    "# features = np.array(digits.data, 'int16') \n",
    "# labels = np.array(digits.target, 'int')\n",
    "# #print features[0].shape\n",
    "\n",
    "# list_hog_fd = []\n",
    "# for feature in features:\n",
    "#     fd = hog(feature.reshape((8, 8)), orientations = 9, pixels_per_cell=(4, 4), \\\n",
    "#              cells_per_block=(1, 1), visualise=False)\n",
    "#     list_hog_fd.append(fd)\n",
    "# hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "\n",
    "\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "# Extract the features and labels\n",
    "features = np.array(dataset.data, 'int16') \n",
    "labels = np.array(dataset.target, 'int')\n",
    "\n",
    "# print features[0].shape\n",
    "# Extract the hog features\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    # Hog Feature for object Identification\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), \\\n",
    "             cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "# Count the number of Samples for every digit\n",
    "print \"Count of digits in dataset\", Counter(labels)\n",
    "accuracy = 0.0\n",
    "\n",
    "X,Y = hog_features,labels\n",
    "Y = Y.reshape(Y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 36), (70000, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part for Handwriten Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1) (100, 36)\n"
     ]
    }
   ],
   "source": [
    "X_Train, X_Test = X[:60000], X[69900:]\n",
    "Y_Train, Y_Test = Y[:60000], Y[69900:]\n",
    "\n",
    "\n",
    "print Y_Train.shape,X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 8.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 0.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 0.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 8.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 0.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 6.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[41m>>Predicted Result 7.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\u001b[32m>>Predicted Result 9.0 and Actual Result 9.0\u001b[0m\n",
      "\n",
      "\n",
      "89 test cases classified correctly out of 100 with an efficiency of 89.0 %\n"
     ]
    }
   ],
   "source": [
    "y_predictions = []\n",
    "y_test = []\n",
    "\n",
    "trainingSet = np.concatenate((X_Train, Y_Train), axis=1)\n",
    "testSet = np.concatenate((X_Test, Y_Test), axis=1)\n",
    "predictions=[]\n",
    "k = 3\n",
    "\n",
    "for x in range(len(testSet)):\n",
    "    neighbors = Find_Neighbors(trainingSet, testSet[x], k)\n",
    "\n",
    "    result = Predict(neighbors)\n",
    "\n",
    "    y_predictions.append(repr(result))\n",
    "    y_test.append(repr(testSet[x][-1]))\n",
    "    \n",
    "accuracy,correct = Find_Accuracy(y_test, y_predictions)\n",
    "\n",
    "print \"\\n\\n\" + str(correct) + \" test cases classified correctly out of \" + \\\n",
    "        str(len(y_test)) + \" with an efficiency of \" + \\\n",
    "            str(accuracy) + \" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 36), (70000, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Handwritten Digit Testing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "2.0\n",
      "5.0\n",
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "8.0\n",
      "9.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "########################################  Photo 1 Testing part    ########################################## \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"photo_1.jpg\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Show the Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "# Training the MNIST dataset\n",
    "trainingSet = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    # Draw the rectangle around the digit..\n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (4, 4))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    \n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    \n",
    "    print result\n",
    "    \n",
    "    cv2.putText(im, str(int(result)), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 3)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One More Testing Image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "5.0\n",
      "2.0"
     ]
    }
   ],
   "source": [
    "####################################  Harsh Handwritting Testing part    #################################### \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"harsh.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the image\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "trainingSet = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (4, 4))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    #print roi_hog_fd\n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    \n",
    "    print result\n",
    "    \n",
    "    cv2.putText(im, str(int(result)), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Testing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "5.0\n",
      "3.0\n",
      "7.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "###################################   Other Handwritting Digit Testing part    ################################### \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"parikh.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 190, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "trainingSet = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (5, 5))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    \n",
    "    k = 3\n",
    "\n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    \n",
    "    print result\n",
    "    \n",
    "    cv2.putText(im, str(int(result)), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now comes to Letter Recognition Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 1) (100, 16)\n"
     ]
    }
   ],
   "source": [
    "##############################     Letter Recognition Training Part    ##################################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Letter Dataset \n",
    "# https://archive.ics.uci.edu/ml/datasets/Letter+Recognition\n",
    "\n",
    "fname = 'letter-recognition.data'\n",
    "\n",
    "data = np.loadtxt(fname, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })\n",
    "\n",
    "X_letter,Y_letter = data[:,1:],data[:,0]\n",
    "Y_letter = Y_letter.reshape(Y_letter.shape[0],1)\n",
    "\n",
    "X_Train, X_Test = X_letter[:19000], X_letter[19900:]\n",
    "Y_Train, Y_Test = Y_letter[:19000], Y_letter[19900:]\n",
    "\n",
    "\n",
    "print Y_Train.shape,X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result H and Actual Result H\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result X and Actual Result X\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result D and Actual Result D\u001b[0m\n",
      "\u001b[32m>>Predicted Result U and Actual Result U\u001b[0m\n",
      "\u001b[32m>>Predicted Result I and Actual Result I\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result U and Actual Result U\u001b[0m\n",
      "\u001b[32m>>Predicted Result X and Actual Result X\u001b[0m\n",
      "\u001b[41m>>Predicted Result B and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result K and Actual Result K\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result X and Actual Result X\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result P and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result K and Actual Result K\u001b[0m\n",
      "\u001b[41m>>Predicted Result O and Actual Result W\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result H and Actual Result H\u001b[0m\n",
      "\u001b[32m>>Predicted Result W and Actual Result W\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result G and Actual Result G\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result P and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result U and Actual Result U\u001b[0m\n",
      "\u001b[32m>>Predicted Result H and Actual Result H\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result B and Actual Result B\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\u001b[32m>>Predicted Result Q and Actual Result Q\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result F and Actual Result F\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result N and Actual Result N\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\u001b[32m>>Predicted Result K and Actual Result K\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result R and Actual Result R\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result Y and Actual Result Y\u001b[0m\n",
      "\u001b[32m>>Predicted Result V and Actual Result V\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result M and Actual Result M\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result L and Actual Result L\u001b[0m\n",
      "\u001b[32m>>Predicted Result D and Actual Result D\u001b[0m\n",
      "\u001b[41m>>Predicted Result F and Actual Result P\u001b[0m\n",
      "\u001b[32m>>Predicted Result W and Actual Result W\u001b[0m\n",
      "\u001b[32m>>Predicted Result O and Actual Result O\u001b[0m\n",
      "\u001b[32m>>Predicted Result E and Actual Result E\u001b[0m\n",
      "\u001b[32m>>Predicted Result J and Actual Result J\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result D and Actual Result D\u001b[0m\n",
      "\u001b[32m>>Predicted Result C and Actual Result C\u001b[0m\n",
      "\u001b[32m>>Predicted Result T and Actual Result T\u001b[0m\n",
      "\u001b[32m>>Predicted Result S and Actual Result S\u001b[0m\n",
      "\u001b[32m>>Predicted Result A and Actual Result A\u001b[0m\n",
      "\n",
      "\n",
      "97 test cases classified correctly out of 100 with an efficiency of 97.0 %\n"
     ]
    }
   ],
   "source": [
    "##############################     Letter Recognition Testing Part    ##################################\n",
    "\n",
    "\n",
    "\n",
    "accuracy = 0.0\n",
    "y_predictions = []\n",
    "y_test = []\n",
    "\n",
    "trainingSet = np.concatenate((X_Train, Y_Train), axis=1)\n",
    "testSet = np.concatenate((X_Test, Y_Test), axis=1)\n",
    "predictions=[]\n",
    "k = 3\n",
    "\n",
    "for x in range(len(testSet)):\n",
    "    neighbors = Find_Neighbors(trainingSet, testSet[x], k)\n",
    "    result = Predict(neighbors)\n",
    "    y_predictions.append(chr(int(result)+65))\n",
    "    y_test.append(chr(int(testSet[x][-1])+65))\n",
    "        \n",
    "accuracy,correct = Find_Accuracy(y_test, y_predictions)\n",
    "\n",
    "#print \"\\n\\nAccuracy is {0} %\".format(accuracy)\n",
    "\n",
    "print \"\\n\\n\" + str(correct) + \" test cases classified correctly out of \" + \\\n",
    "        str(len(y_test)) + \" with an efficiency of \" + \\\n",
    "            str(accuracy) + \" %\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before X Features Dimention\n",
      "(20000, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['digits_knn_letters.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the modules\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "fname = 'letter-recognition.data'\n",
    "\n",
    "data = np.loadtxt(fname, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })\n",
    "\n",
    "X_letter,Y_letter = data[:,1:],data[:,0]\n",
    "\n",
    "X_letter = np.array(X_letter,'int16')\n",
    "Y_letter = np.array(Y_letter,'int')\n",
    "\n",
    "print \"Before X Features Dimention\"\n",
    "\n",
    "print X_letter.shape\n",
    "list_hog_fd = []\n",
    "\n",
    "for feature in X_letter:\n",
    "    # Hog Feature for object Identification\n",
    "    fd = hog(feature.reshape((4, 4)), orientations=9, pixels_per_cell=(2, 2), \\\n",
    "             cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "\n",
    "#clf = LinearSVC()\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Perform the training\n",
    "\n",
    "neigh.fit(hog_features, Y_letter) \n",
    "\n",
    "# Save the classifier\n",
    "joblib.dump(neigh, \"digits_knn_letters.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "B\n",
      "K\n",
      "N\n",
      "Q\n",
      "A\n",
      "E\n",
      "B\n",
      "A\n",
      "D\n",
      "E\n",
      "W\n",
      "O\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "#####################      Letters Image Extraction      ###################\n",
    "\n",
    "\n",
    "import cv2\n",
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "\n",
    "# Load the classifier\n",
    "\n",
    "\n",
    "# print hog_features.shape\n",
    "\n",
    "# X_letter = hog_features\n",
    "# Y_letter = Y_letter.reshape(Y_letter.shape[0],1)\n",
    "\n",
    "\n",
    "neigh = joblib.load(\"digits_knn_letters.pkl\")\n",
    "\n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"letters.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "ret, im_th = cv2.threshold(im_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "#trainingSet = np.concatenate((X_letter, Y_letter), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (4, 4), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (3, 3))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(2, 2), cells_per_block=(1, 1), visualise=False)\n",
    "\n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    nbr = neigh.predict(np.array([roi_hog_fd], 'float64'))\n",
    "    print chr(int(nbr[0])+65)\n",
    "    \n",
    "    cv2.putText(im, chr(int(nbr[0])+65), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for HOG Feature for Letter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before X Features Dimention\n",
      "(20000, 16)\n",
      "\n",
      "After X Features Dimention\n",
      "(20000, 36)\n"
     ]
    }
   ],
   "source": [
    "########################  Letter Recognition Training Part for HOG Features #########################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "fname = 'letter-recognition.data'\n",
    "\n",
    "data = np.loadtxt(fname, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })\n",
    "\n",
    "X_letter,Y_letter = data[:,1:],data[:,0]\n",
    "\n",
    "X_letter = np.array(X_letter,'int16')\n",
    "Y_letter = np.array(Y_letter,'int')\n",
    "\n",
    "print \"Before X Features Dimention\"\n",
    "\n",
    "print X_letter.shape\n",
    "list_hog_fd = []\n",
    "\n",
    "for feature in X_letter:\n",
    "    # Hog Feature for object Identification\n",
    "    fd = hog(feature.reshape((4, 4)), orientations=9, pixels_per_cell=(2, 2), \\\n",
    "             cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "accuracy = 0.0\n",
    "\n",
    "print \"\\nAfter X Features Dimention\"\n",
    "\n",
    "print hog_features.shape\n",
    "\n",
    "X_letter = hog_features\n",
    "Y_letter = Y_letter.reshape(Y_letter.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 36), (20000, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_letter.shape,Y_letter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Testing Data for Letter Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for a moment......\n",
      "\n",
      "\n",
      "My Predicted Result \n",
      "\n",
      "B\n",
      "K\n",
      "N\n",
      "A\n",
      "A\n",
      "Q\n",
      "B\n",
      "A\n",
      "D\n",
      "E\n",
      "W\n",
      "O\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "##################################   Handwritten Letters Testing part    #################################### \n",
    "\n",
    "# Read the input image \n",
    "\n",
    "im = cv2.imread(\"dipen_letter.png\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "############## Original Image  ###################\n",
    "\n",
    "cv2.imshow(\"Original Image\",im)\n",
    "\n",
    "ret, im_th = cv2.threshold(im_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Threshold\",im_th)\n",
    "\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "testingSet = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "trainingSet = np.concatenate((X_letter, Y_letter), axis=1)\n",
    "\n",
    "print \"Wait for a moment......\"\n",
    "\n",
    "print \"\\n\\nMy Predicted Result \\n\"\n",
    "\n",
    "for rect in testingSet:\n",
    "    \n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    \n",
    "    roi = cv2.resize(roi, (4, 4), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    roi = cv2.dilate(roi, (3, 3))\n",
    "    \n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(2, 2), cells_per_block=(1, 1), visualise=False)\n",
    "\n",
    "    k = 3\n",
    "    \n",
    "    #########################  Implementation of Algorithm   ##################################\n",
    "    \n",
    "    neighbors = Find_Neighbors(trainingSet, roi_hog_fd, k)\n",
    "    \n",
    "    result = Predict(neighbors)\n",
    "    print str(chr(int(result)+65))\n",
    "    cv2.putText(im, chr(int(result)+65), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Resulting Image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Inbuilt Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy:  90.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "#########################  Inbuilt Method for KNN    ##########################\n",
    "\n",
    "# http://brianfarris.me/static/digit_recognizer.html\n",
    "\n",
    "\n",
    "x_train, x_test = X[:60000], X[60000:]\n",
    "y_train, y_test = Y[:60000], Y[60000:]\n",
    "\n",
    "\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(x_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(x_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print \"K Nearest Neighbors Accuracy: \",(acc_knn*100), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
